import streamlit as st
import onnxruntime as ort
from PIL import Image
import numpy as np

# Ø¥Ø¹Ø¯Ø§Ø¯ ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„ØªØ·Ø¨ÙŠÙ‚
st.set_page_config(page_title="Arabic Sign Language Translator", layout="centered")
st.title("ğŸ¤Ÿ Arabic Sign Language Translator")
st.write("Take a photo or upload an image of an Arabic sign letter to translate it!")

# 1. ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ (ONNX)
@st.cache_resource
def load_model():
    # ØªØ£ÙƒØ¯ Ø£Ù† Ù…Ù„Ù Ø§Ù„Ù€ ONNX Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ Ù†ÙØ³ Ù…Ø¬Ù„Ø¯ Ù…Ù„Ù Ø§Ù„Ù€ app.py
    return ort.InferenceSession("sign_language_model.onnx")

session = load_model()

# 2. Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø­Ø±ÙˆÙ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© (Ù†ÙØ³ Ø§Ù„ØªØ±ØªÙŠØ¨ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ÙÙŠ Ø§Ù„ØªØ¯Ø±ÙŠØ¨)
classes = ['Ø£Ù„Ù', 'Ø¨Ø§Ø¡', 'ØªØ§Ø¡', 'Ø«Ø§Ø¡', 'Ø¬ÙŠÙ…', 'Ø­Ø§Ø¡', 'Ø®Ø§Ø¡', 'Ø¯Ø§Ù„', 'Ø°Ø§Ù„', 'Ø±Ø§Ø¡', 'Ø²Ø§ÙŠ', 'Ø³ÙŠÙ†', 'Ø´ÙŠÙ†', 'ØµØ§Ø¯', 'Ø¶Ø§Ø¯', 'Ø·Ø§Ø¡', 'Ø¸Ø§Ø¡', 'Ø¹ÙŠÙ†', 'ØºÙŠÙ†', 'ÙØ§Ø¡', 'Ù‚Ø§Ù', 'ÙƒØ§Ù', 'Ù„Ø§Ù…', 'Ù…ÙŠÙ…', 'Ù†ÙˆÙ†', 'Ù‡Ø§Ø¡', 'ÙˆØ§Ùˆ', 'ÙŠØ§Ø¡']

# 3. Ø§Ø®ØªÙŠØ§Ø± Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„ (ÙƒØ§Ù…ÙŠØ±Ø§ Ø£Ùˆ Ø±ÙØ¹ Ù…Ù„Ù)
input_method = st.radio("Select input method:", ("Camera", "Upload File"))

img_file = None
if input_method == "Camera":
    img_file = st.camera_input("Capture sign")
else:
    img_file = st.file_uploader("Choose an image...", type=["jpg", "jpeg", "png"])

# 4. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØªÙˆÙ‚Ø¹ Ø¥Ø°Ø§ ØªÙ… ØªÙˆÙÙŠØ± ØµÙˆØ±Ø©
if img_file is not None:
    # ÙØªØ­ Ø§Ù„ØµÙˆØ±Ø© ÙˆØªØ­ÙˆÙŠÙ„Ù‡Ø§ Ù„Ø±Ù…Ø§Ø¯ÙŠ (Grayscale)
    image = Image.open(img_file).convert('L') 
    st.image(image, caption='Processed Image', width=300)
    
    # 5. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±Ø© Ù„ØªÙ†Ø§Ø³Ø¨ Ù…Ø¯Ø®Ù„Ø§Øª Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ (64x64)
    img = image.resize((64, 64))
    img_array = np.array(img).astype(np.float32)
    
    # Ø§Ù„Ù€ Normalize (Ù†ÙØ³ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ÙÙŠ Notebook ØªÙ…Ø§Ù…Ø§Ù‹)
    img_array = (img_array / 255.0 - 0.5) / 0.5  
    
    # Ø¥Ø¹Ø§Ø¯Ø© ØªØ´ÙƒÙŠÙ„ Ø§Ù„Ù…ØµÙÙˆÙØ© Ù„ØªÙ†Ø§Ø³Ø¨ Ø£Ø¨Ø¹Ø§Ø¯ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ (Batch=1, Channel=1, H=64, W=64)
    img_array = img_array.reshape(1, 1, 64, 64) 

    # 6. Ø§Ù„ØªÙˆÙ‚Ø¹ (Inference)
    st.write("---")
    st.write("ğŸ” **Analyzing...**")
    
    inputs = {session.get_inputs()[0].name: img_array}
    outputs = session.run(None, inputs)
    prediction = np.argmax(outputs[0])
    
    # 7. Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ© Ø¨Ø´ÙƒÙ„ Ù…Ù…ÙŠØ²
    st.balloons() # ØªØ£Ø«ÙŠØ± Ø§Ø­ØªÙØ§Ù„ÙŠ Ø¨Ø³ÙŠØ· Ø¹Ù†Ø¯ Ø§Ù„Ù†Ø¬Ø§Ø­
    st.success(f"### The predicted letter is: **{classes[prediction]}**")